{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd977542-d739-44d3-bec0-50be2f8247d9",
   "metadata": {},
   "source": [
    "### This notebook demonstrates padding numpy arrays or tensors with `tf.data.padded_batch` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43a31def-a072-4749-9b96-de8ee7532690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-26 17:14:47.375737: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-26 17:14:47.579788: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-26 17:14:47.579813: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-26 17:14:47.630419: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-26 17:14:48.905535: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-26 17:14:48.905618: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-26 17:14:48.905627: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ac0907-1a55-4e41-af63-9551f2ef51e8",
   "metadata": {},
   "source": [
    "### Combines consecutive elements of this dataset into padded batches.\n",
    "\n",
    "```python\n",
    "padded_batch(\n",
    "    batch_size,\n",
    "    padded_shapes=None,\n",
    "    padding_values=None,\n",
    "    drop_remainder=False,\n",
    "    name=None\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bba78c6-8a07-4ed5-a4c2-be5fcee21e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[2 2]\n",
      "[3 3 3]\n",
      "[4 4 4 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-26 17:14:50.630934: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-10-26 17:14:50.630964: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-26 17:14:50.630986: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (debonair): /proc/driver/nvidia/version does not exist\n",
      "2022-10-26 17:14:50.631395: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "A = (tf.data.Dataset.range(1, 5)\n",
    "     .map(lambda x: tf.fill([x], x)))\n",
    "\n",
    "\n",
    "for element in A.as_numpy_iterator():\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a0aef7f-5eca-4871-b9fc-ac9886c8af51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [2 2]]\n",
      "[[3 3 3 0]\n",
      " [4 4 4 4]]\n"
     ]
    }
   ],
   "source": [
    "#Pad the smallest per-batch size that fits all elements.\n",
    "B = A.padded_batch(batch_size = 2)\n",
    "\n",
    "for element in B.as_numpy_iterator():\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aed12799-9b1c-4a82-8426-8d1285ac99d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0]\n",
      " [2 2 0 0 0]]\n",
      "[[3 3 3 0 0]\n",
      " [4 4 4 4 0]]\n"
     ]
    }
   ],
   "source": [
    "#Pad to a fixed size.\n",
    "C = A.padded_batch(batch_size = 2, padded_shapes = 5)\n",
    "\n",
    "for element in C.as_numpy_iterator():\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3d93a23-f924-4465-82a9-5d60fa298b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([1, 2, 3], [10]), ([4, 5], [11, 12])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Components of nested elements can be padded independently.\n",
    "elements = [([1, 2, 3], [10]),\n",
    "            ([4, 5], [11, 12])]\n",
    "\n",
    "elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c457c2a5-9c4d-4a02-a1e5-48c319a38d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([[1, 2, 3, 0],\n",
       "         [4, 5, 0, 0]], dtype=int32),\n",
       "  array([[10,  0],\n",
       "         [11, 12]], dtype=int32))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: iter(elements), (tf.int32, tf.int32))\n",
    "\n",
    "# Pad the first component of the tuple to length 4 and the second component to the smallest size that fits.\n",
    "dataset = dataset.padded_batch(batch_size=2, \n",
    "                               padded_shapes=([4], [None]))\n",
    "\n",
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7224f70-a599-4bde-a348-fcfc5c6cd539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[1, 0],\n",
      "       [2, 2]]), array([[1, 0],\n",
      "       [2, 2]]))\n",
      "(array([[3, 3, 3, 0],\n",
      "       [4, 4, 4, 4]]), array([[3, 3, 3, 0],\n",
      "       [4, 4, 4, 4]]))\n"
     ]
    }
   ],
   "source": [
    "#Pad with a single value and multiple components.\n",
    "E = tf.data.Dataset.zip((A, A)).padded_batch(batch_size = 2)\n",
    "\n",
    "for element in E.as_numpy_iterator():\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd67428e-d80f-4b9a-96cc-022de05b10a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
